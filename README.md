# LangGraph Document Service â€“ Documentation (v1.0)

---

## 1Â Â·Â Overview

A microâ€‘service that ingests arbitrary documents (PDF, DOCX, TXT,â€¯â€¦) and exposes:

- **Semantic Q&A** (`GET /ask`)
- **Multiâ€‘document summarisation** (`GET /summary`)
- **Document catalogue & lifeâ€‘cycle management**

Key traitsÂ Â â–¶ï¸

- **FastAPI** REST API
- **LangChain + LangGraph** orchestration
- **OpenAI** GPTâ€‘4oâ€‘mini + textâ€‘embeddingâ€‘adaâ€‘002
- **Persistent vector store** â€“Â ChromaDB (per document directory)
- **Relational metadata** â€“Â SQLModel (SQLite / PostgreSQL)
- **Background ingestion** â€“Â CeleryÂ +Â Redis

---

## 2Â Â·Â Highâ€‘level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   1Â HTTPÂ POST    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”‚Â Â FastAPIÂ /Â Gunicorn â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚  (webÂ pod)         â”‚
        â–²                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚2Â statusÂ pollsÂ /Â queries            â”‚enqueue task
        â”‚                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  4Â storeÂ metadata   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚    CeleryÂ worker   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚  parse â†’ embed     â”‚
                                    â”‚  persistÂ vectors   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  3Â vectorÂ persist   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ ChromaDB dir â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Upload**Â â†’ API saves a *processing* record and enqueues `ingest_task`.
2. Client polls `/documents/{id}` until `status: ready`.
3. Worker writes embeddings to `vector_db/<doc_id>/` (Chroma)Â + `chunks.json`.
4. Worker updates DB (`status: ready`, `n_chunks`).

---

## 3Â Â·Â Installation (local dev)

```bash
# clone repo
pip install -r requirements.txt  # or copy the list below
export OPENAI_API_KEY=skâ€‘â€¦
# optional: run postgres; fallback to SQLite works out of the box
redis-server &                    # needs Redis â‰¥â€¯6
uvicorn agent_app:app --reload    # web pod
celery -A agent_app.celery_app worker -l info  # worker pod
```

**Dependencies**

```
fastapi "uvicorn[standard]" langchain langchain-openai langgraph
sqlmodel sqlalchemy psycopg2-binary  # (or aiosqlite)
docling chromadb tiktoken numpy
celery redis
```

---

## 4Â Â·Â Environment variables

| Var              | Default                    | Purpose                 |
| ---------------- | -------------------------- | ----------------------- |
| `OPENAI_API_KEY` | â€”                          | calls GPT & embeddings  |
| `DATABASE_URL`   | `sqlite:///./app.db`       | SQLModel engine         |
| `REDIS_URL`      | `redis://localhost:6379/0` | Celery broker / backend |

---

## 5Â Â·Â Directory layout

```
.
â”œâ”€ agent_app.py          # FastAPI + Celery codebase (see canvas)
â”œâ”€ vector_db/            # one subâ€‘dir per document (Chroma index)
â”‚   â””â”€ <doc_id>/
â”‚       â”œâ”€ index.sqlite  # Chroma DB
â”‚       â””â”€ chunks.json   # raw chunk texts
â””â”€ app.db                # SQLite (if PostgreSQL not configured)
```

---

## 6Â Â·Â API Reference

### 6.1Â Upload Document

`POST /documents`

| Field                      | Type                | Notes                |
| -------------------------- | ------------------- | -------------------- |
| fileÂ (ğŸ—‹)                  | multipart/formâ€‘data | any supported format |
| **Returns** `202Â Accepted` |                     |                      |

```json
{ "doc_id": "<uuid>", "status": "processing" }
```

### 6.2Â List Documents

`GET /documents`

```json
[
  {"id":"â€¦","name":"report.pdf","status":"ready","n_chunks":28,"created_at":"â€¦"},
  â€¦
]
```

### 6.3Â Document Detail / Status

`GET /documents/{id}` â†’ same schema as above.

### 6.4Â Delete Document

`DELETE /documents/{id}` â†’ `{ "status": "deleted", "doc_id": "â€¦" }`

### 6.5Â Multiâ€‘Document Summary

`GET /summary?doc_id=id1&doc_id=id2&length=medium`

| Query                                | Description                                  |
| ------------------------------------ | -------------------------------------------- |
| `doc_id`                             | repeatable â€“ one or more UUIDs               |
| `length`                             | `short`â€¯â‰ˆâ€¯3 sent., `medium`â€¯â‰ˆâ€¯8, `long`â€¯â‰ˆâ€¯15 |
| **409** if any document not `ready`. |                                              |

### 6.6Â Semantic Q&A

`GET /ask?q=<question>&doc_id=<id>&doc_id=<id>&top_k=3`

- `q`Â â€“ freeâ€‘text question
- `top_k`Â â€“ retrieved chunks per document (defaultÂ 3)

---

## 7Â Â·Â Database Schema

```sql
CREATE TABLE doc (
  id TEXT PRIMARY KEY,
  name TEXT NOT NULL,
  status TEXT NOT NULL,       -- processing | ready | failed
  n_chunks INTEGER,
  created_at TIMESTAMP NOT NULL
);
```

---

## 8Â Â·Â Background Ingestion Flow

1. **Celery task **``
   - parse â†’ `docling` â†’ Markdown
   - split â†’ `RecursiveCharacterTextSplitter`
   - embed & persist â†’ `Chroma.from_documents(..., persist_directory=â€¦)`
   - save chunks â†’ `chunks.json`
   - update `doc` row (`ready` + `n_chunks`)
2. Failure sets `status: failed` and keeps logs.

---

## 9Â Â·Â How to Deploy

- **Docker / Compose** â€“Â singleâ€‘host dev:
  - `api` image (FastAPI + Gunicorn)
  - `worker` image (Celery)
  - `redis`
  - `postgres`
- **Kubernetes** â€“Â 2Â deployments (`api`, `worker`) + 2 stateful services (`redis`, `postgres`).
- Mount `vector_db` on persistent volume claim (PVC) or switch to S3â€‘backed Chroma.

---

## 10Â Â·Â Testing

```bash
pytest tests/            # unit + httpx integration tests
pytest -m e2e            # requires OPENAI_API_KEY set
```

Mock LLM via `langchain.chat_models.fake.FakeListChatModel` for CI.

---

## 11Â Â·Â Extension Points

- Swap Chroma for Weaviate / Pinecone by replacing `langchain.vectorstores.Chroma` wrapper.
- Add topic segmentation endpoint (`/segments`) using embeddings + Kâ€‘Means.
- Enable SSE / WebSocket to stream token responses or ingest task progress.
- Implement OAuthÂ / JWT to secure endpoints per user.

---

Â©Â 2025Â LangGraph DocÂ Service â€¢ MIT

